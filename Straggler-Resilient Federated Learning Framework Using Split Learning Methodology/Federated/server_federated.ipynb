{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Federated 1D-CNN Server Side\n",
    "This code is the server part of ECG federated 1D-CNN model for **multi** client and a server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds = 400\n",
    "local_epoch = 1\n",
    "users = 2 # number of clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "\n",
    "import socket\n",
    "import struct\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from threading import Thread\n",
    "from threading import Lock\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch layer modules for *Conv1D* Network\n",
    "\n",
    "\n",
    "\n",
    "### `Conv1d` layer\n",
    "- `torch.nn.Conv1d(in_channels, out_channels, kernel_size)`\n",
    "\n",
    "### `MaxPool1d` layer\n",
    "- `torch.nn.MaxPool1d(kernel_size, stride=None)`\n",
    "- Parameter `stride` follows `kernel_size`.\n",
    "\n",
    "### `ReLU` layer\n",
    "- `torch.nn.ReLU()`\n",
    "\n",
    "### `Linear` layer\n",
    "- `torch.nn.Linear(in_features, out_features, bias=True)`\n",
    "\n",
    "### `Softmax` layer\n",
    "- `torch.nn.Softmax(dim=None)`\n",
    "- Parameter `dim` is usually set to `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct 1D-CNN ECG classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EcgConv1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EcgConv1d, self).__init__()        \n",
    "        self.conv1 = nn.Conv1d(1, 16, 7)  # 124 x 16        \n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.pool1 = nn.MaxPool1d(2)  # 62 x 16\n",
    "        self.conv2 = nn.Conv1d(16, 16, 5)  # 58 x 16\n",
    "        self.relu2 = nn.LeakyReLU()        \n",
    "        self.conv3 = nn.Conv1d(16, 16, 5)  # 54 x 16\n",
    "        self.relu3 = nn.LeakyReLU()        \n",
    "        self.conv4 = nn.Conv1d(16, 16, 5)  # 50 x 16\n",
    "        self.relu4 = nn.LeakyReLU()\n",
    "        self.pool4 = nn.MaxPool1d(2)  # 25 x 16\n",
    "        self.linear5 = nn.Linear(25 * 16, 128)\n",
    "        self.relu5 = nn.LeakyReLU()        \n",
    "        self.linear6 = nn.Linear(128, 5)\n",
    "        self.softmax6 = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)        \n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "        x = x.view(-1, 25 * 16)\n",
    "        x = self.linear5(x)\n",
    "        x = self.relu5(x)        \n",
    "        x = self.linear6(x)\n",
    "        x = self.softmax6(x)\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EcgConv1d(\n",
       "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,))\n",
       "  (relu1): LeakyReLU(negative_slope=0.01)\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(16, 16, kernel_size=(5,), stride=(1,))\n",
       "  (relu2): LeakyReLU(negative_slope=0.01)\n",
       "  (conv3): Conv1d(16, 16, kernel_size=(5,), stride=(1,))\n",
       "  (relu3): LeakyReLU(negative_slope=0.01)\n",
       "  (conv4): Conv1d(16, 16, kernel_size=(5,), stride=(1,))\n",
       "  (relu4): LeakyReLU(negative_slope=0.01)\n",
       "  (pool4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (linear5): Linear(in_features=400, out_features=128, bias=True)\n",
       "  (relu5): LeakyReLU(negative_slope=0.01)\n",
       "  (linear6): Linear(in_features=128, out_features=5, bias=True)\n",
       "  (softmax6): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_net = EcgConv1d()\n",
    "ecg_net.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientsoclist = [0]*users\n",
    "\n",
    "start_time = 0\n",
    "weight_count = 0\n",
    "\n",
    "global_weights = copy.deepcopy(ecg_net.state_dict())\n",
    "\n",
    "datasetsize = [0]*users\n",
    "weights_list = [0]*users\n",
    "\n",
    "lock = Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comunication overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sendsize_list = []\n",
    "total_receivesize_list = []\n",
    "\n",
    "client_sendsize_list = [[] for i in range(users)]\n",
    "client_receivesize_list = [[] for i in range(users)]\n",
    "\n",
    "train_sendsize_list = [] \n",
    "train_receivesize_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socket initialization\n",
    "### Set host address and port number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required socket functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    l_send = len(msg)\n",
    "    msg = struct.pack('>I', l_send) + msg\n",
    "    sock.sendall(msg)\n",
    "    return l_send\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg, msglen\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def average_weights(w, datasize):\n",
    "    \"\"\"\n",
    "    Returns the average of the weights.\n",
    "    \"\"\"\n",
    "        \n",
    "    for i, data in enumerate(datasize):\n",
    "        for key in w[i].keys():\n",
    "            w[i][key] *= float(data)\n",
    "    \n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    \n",
    "    \n",
    "\n",
    "# when client use only one kinds of device\n",
    "\n",
    "    for key in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] += w[i][key]\n",
    "        w_avg[key] = torch.div(w_avg[key], float(sum(datasize)))\n",
    "\n",
    "# when client use various devices (cpu, gpu) you need to use it instead\n",
    "#\n",
    "#     for key, val in w_avg.items():\n",
    "#         common_device = val.device\n",
    "#         break\n",
    "#     for key in w_avg.keys():\n",
    "#         for i in range(1, len(w)):\n",
    "#             if common_device == 'cpu':\n",
    "#                 w_avg[key] += w[i][key].cpu()\n",
    "#             else:\n",
    "#                 w_avg[key] += w[i][key].cuda()\n",
    "#         w_avg[key] = torch.div(w_avg[key], float(sum(datasize)))\n",
    "\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receive users before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_thread(func, num_user):\n",
    "    global clientsoclist\n",
    "    global start_time\n",
    "    \n",
    "    thrs = []\n",
    "    for i in range(num_user):\n",
    "        conn, addr = s.accept()\n",
    "        print('Conntected with', addr)\n",
    "        # append client socket on list\n",
    "        clientsoclist[i] = conn\n",
    "        args = (i, num_user, conn)\n",
    "        thread = Thread(target=func, args=args)\n",
    "        thrs.append(thread)\n",
    "        thread.start()\n",
    "    print(\"timmer start!\")\n",
    "    start_time = time.time()    # store start time\n",
    "    for thread in thrs:\n",
    "        thread.join()\n",
    "    end_time = time.time()  # store end time\n",
    "    print(\"TrainingTime: {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive(userid, num_users, conn): #thread for receive clients\n",
    "    global weight_count\n",
    "    \n",
    "    global datasetsize\n",
    "\n",
    "\n",
    "    msg = {\n",
    "        'rounds': rounds,\n",
    "        'client_id': userid,\n",
    "        'local_epoch': local_epoch\n",
    "    }\n",
    "\n",
    "    datasize = send_msg(conn, msg)    #send epoch\n",
    "    total_sendsize_list.append(datasize)\n",
    "    client_sendsize_list[userid].append(datasize)\n",
    "\n",
    "    train_dataset_size, datasize = recv_msg(conn)    # get total_batch of train dataset\n",
    "    total_receivesize_list.append(datasize)\n",
    "    client_receivesize_list[userid].append(datasize)\n",
    "    \n",
    "    \n",
    "    with lock:\n",
    "        datasetsize[userid] = train_dataset_size\n",
    "        weight_count += 1\n",
    "    \n",
    "    train(userid, train_dataset_size, num_users, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(userid, train_dataset_size, num_users, client_conn):\n",
    "    global weights_list\n",
    "    global global_weights\n",
    "    global weight_count\n",
    "    global ecg_net\n",
    "    global val_acc\n",
    "    \n",
    "    for r in range(rounds):\n",
    "        with lock:\n",
    "            if weight_count == num_users:\n",
    "                for i, conn in enumerate(clientsoclist):\n",
    "                    datasize = send_msg(conn, global_weights)\n",
    "                    total_sendsize_list.append(datasize)\n",
    "                    client_sendsize_list[i].append(datasize)\n",
    "                    train_sendsize_list.append(datasize)\n",
    "                    weight_count = 0\n",
    "\n",
    "        client_weights, datasize = recv_msg(client_conn)\n",
    "        total_receivesize_list.append(datasize)\n",
    "        client_receivesize_list[userid].append(datasize)\n",
    "        train_receivesize_list.append(datasize)\n",
    "\n",
    "        weights_list[userid] = client_weights\n",
    "        print(\"User\" + str(userid) + \"'s Round \" + str(r + 1) +  \" is done\")\n",
    "        with lock:\n",
    "            weight_count += 1\n",
    "            if weight_count == num_users:\n",
    "                #average\n",
    "                global_weights = average_weights(weights_list, datasetsize)\n",
    "                \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192.168.83.1\n"
     ]
    }
   ],
   "source": [
    "host = socket.gethostbyname(socket.gethostname())\n",
    "port = 10080\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = socket.socket()\n",
    "s.bind((host, port))\n",
    "s.listen(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the server socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conntected with ('192.168.83.1', 5455)\n",
      "Conntected with ('192.168.83.1', 5555)\n",
      "timmer start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlaal\\anaconda3\\envs\\py36\\lib\\site-packages\\torch\\storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User0's Round 1 is done\n",
      "User1's Round 1 is done\n",
      "User1's Round 2 is done\n",
      "User0's Round 2 is done\n",
      "User0's Round 3 is done\n",
      "User1's Round 3 is done\n",
      "User0's Round 4 is done\n",
      "User1's Round 4 is done\n",
      "User0's Round 5 is done\n",
      "User1's Round 5 is done\n",
      "User1's Round 6 is done\n",
      "User0's Round 6 is done\n",
      "User1's Round 7 is done\n",
      "User0's Round 7 is done\n",
      "User1's Round 8 is done\n",
      "User0's Round 8 is done\n",
      "User1's Round 9 is done\n",
      "User0's Round 9 is done\n",
      "User1's Round 10 is done\n",
      "User0's Round 10 is done\n",
      "User0's Round 11 is done\n",
      "User1's Round 11 is done\n",
      "User1's Round 12 is done\n",
      "User0's Round 12 is done\n",
      "User1's Round 13 is done\n",
      "User0's Round 13 is done\n",
      "User0's Round 14 is done\n",
      "User1's Round 14 is done\n",
      "User0's Round 15 is done\n",
      "User1's Round 15 is done\n",
      "User1's Round 16 is done\n",
      "User0's Round 16 is done\n",
      "User1's Round 17 is done\n",
      "User0's Round 17 is done\n",
      "User1's Round 18 is done\n",
      "User0's Round 18 is done\n",
      "User1's Round 19 is done\n",
      "User0's Round 19 is done\n",
      "User1's Round 20 is done\n",
      "User0's Round 20 is done\n",
      "User1's Round 21 is done\n",
      "User0's Round 21 is done\n",
      "User1's Round 22 is done\n",
      "User0's Round 22 is done\n",
      "User1's Round 23 is done\n",
      "User0's Round 23 is done\n",
      "User1's Round 24 is done\n",
      "User0's Round 24 is done\n",
      "User1's Round 25 is done\n",
      "User0's Round 25 is done\n",
      "User1's Round 26 is done\n",
      "User0's Round 26 is done\n",
      "User0's Round 27 is done\n",
      "User1's Round 27 is done\n",
      "User1's Round 28 is done\n",
      "User0's Round 28 is done\n",
      "User0's Round 29 is done\n",
      "User1's Round 29 is done\n",
      "User1's Round 30 is done\n",
      "User0's Round 30 is done\n",
      "User1's Round 31 is done\n",
      "User0's Round 31 is done\n",
      "User1's Round 32 is done\n",
      "User0's Round 32 is done\n",
      "User1's Round 33 is done\n",
      "User0's Round 33 is done\n",
      "User1's Round 34 is done\n",
      "User0's Round 34 is done\n",
      "User1's Round 35 is done\n",
      "User0's Round 35 is done\n",
      "User1's Round 36 is done\n",
      "User0's Round 36 is done\n",
      "User1's Round 37 is done\n",
      "User0's Round 37 is done\n",
      "User1's Round 38 is done\n",
      "User0's Round 38 is done\n",
      "User1's Round 39 is done\n",
      "User0's Round 39 is done\n",
      "User1's Round 40 is done\n",
      "User0's Round 40 is done\n",
      "User0's Round 41 is done\n",
      "User1's Round 41 is done\n",
      "User1's Round 42 is done\n",
      "User0's Round 42 is done\n",
      "User0's Round 43 is done\n",
      "User1's Round 43 is done\n",
      "User1's Round 44 is done\n",
      "User0's Round 44 is done\n",
      "User0's Round 45 is done\n",
      "User1's Round 45 is done\n",
      "User1's Round 46 is done\n",
      "User0's Round 46 is done\n",
      "User1's Round 47 is done\n",
      "User0's Round 47 is done\n",
      "User1's Round 48 is done\n",
      "User0's Round 48 is done\n",
      "User0's Round 49 is done\n",
      "User1's Round 49 is done\n",
      "User1's Round 50 is done\n",
      "User0's Round 50 is done\n",
      "User0's Round 51 is done\n",
      "User1's Round 51 is done\n",
      "User1's Round 52 is done\n",
      "User0's Round 52 is done\n",
      "User1's Round 53 is done\n",
      "User0's Round 53 is done\n",
      "User1's Round 54 is done\n",
      "User0's Round 54 is done\n",
      "User0's Round 55 is done\n",
      "User1's Round 55 is done\n",
      "User1's Round 56 is done\n",
      "User0's Round 56 is done\n",
      "User0's Round 57 is done\n",
      "User1's Round 57 is done\n",
      "User1's Round 58 is done\n",
      "User0's Round 58 is done\n",
      "User1's Round 59 is done\n",
      "User0's Round 59 is done\n",
      "User1's Round 60 is done\n",
      "User0's Round 60 is done\n",
      "User1's Round 61 is done\n",
      "User0's Round 61 is done\n",
      "User0's Round 62 is done\n",
      "User1's Round 62 is done\n",
      "User1's Round 63 is done\n",
      "User0's Round 63 is done\n",
      "User0's Round 64 is done\n",
      "User1's Round 64 is done\n",
      "User0's Round 65 is done\n",
      "User1's Round 65 is done\n",
      "User1's Round 66 is done\n",
      "User0's Round 66 is done\n",
      "User1's Round 67 is done\n",
      "User0's Round 67 is done\n",
      "User1's Round 68 is done\n",
      "User0's Round 68 is done\n",
      "User0's Round 69 is done\n",
      "User1's Round 69 is done\n",
      "User1's Round 70 is done\n",
      "User0's Round 70 is done\n",
      "User1's Round 71 is done\n",
      "User0's Round 71 is done\n",
      "User1's Round 72 is done\n",
      "User0's Round 72 is done\n",
      "User1's Round 73 is done\n",
      "User0's Round 73 is done\n",
      "User1's Round 74 is done\n",
      "User0's Round 74 is done\n",
      "User0's Round 75 is done\n",
      "User1's Round 75 is done\n",
      "User1's Round 76 is done\n",
      "User0's Round 76 is done\n",
      "User0's Round 77 is done\n",
      "User1's Round 77 is done\n",
      "User0's Round 78 is done\n",
      "User1's Round 78 is done\n",
      "User1's Round 79 is done\n",
      "User0's Round 79 is done\n",
      "User0's Round 80 is done\n",
      "User1's Round 80 is done\n",
      "User0's Round 81 is done\n",
      "User1's Round 81 is done\n",
      "User1's Round 82 is done\n",
      "User0's Round 82 is done\n",
      "User0's Round 83 is done\n",
      "User1's Round 83 is done\n",
      "User1's Round 84 is done\n",
      "User0's Round 84 is done\n",
      "User0's Round 85 is done\n",
      "User1's Round 85 is done\n",
      "User1's Round 86 is done\n",
      "User0's Round 86 is done\n",
      "User1's Round 87 is done\n",
      "User0's Round 87 is done\n",
      "User1's Round 88 is done\n",
      "User0's Round 88 is done\n",
      "User1's Round 89 is done\n",
      "User0's Round 89 is done\n",
      "User1's Round 90 is done\n",
      "User0's Round 90 is done\n",
      "User1's Round 91 is done\n",
      "User0's Round 91 is done\n",
      "User1's Round 92 is done\n",
      "User0's Round 92 is done\n",
      "User1's Round 93 is done\n",
      "User0's Round 93 is done\n",
      "User0's Round 94 is done\n",
      "User1's Round 94 is done\n",
      "User0's Round 95 is done\n",
      "User1's Round 95 is done\n",
      "User0's Round 96 is done\n",
      "User1's Round 96 is done\n",
      "User1's Round 97 is done\n",
      "User0's Round 97 is done\n",
      "User0's Round 98 is done\n",
      "User1's Round 98 is done\n",
      "User1's Round 99 is done\n",
      "User0's Round 99 is done\n",
      "User0's Round 100 is done\n",
      "User1's Round 100 is done\n",
      "TrainingTime: 351.40712785720825 sec\n"
     ]
    }
   ],
   "source": [
    "run_thread(receive, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingTime: 351.4171006679535 sec\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()  # store end time\n",
    "print(\"TrainingTime: {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print all of communication overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---total_sendsize_list---\n",
      "total_sendsize size: 45635122 bytes\n",
      "\n",
      "\n",
      "---total_receivesize_list---\n",
      "total receive sizes: 45635012 bytes\n",
      "\n",
      "\n",
      "---client_sendsize_list(user0)---\n",
      "total client_sendsizes(user0): 22817561 bytes\n",
      "\n",
      "\n",
      "---client_receivesize_list(user0)---\n",
      "total client_receive sizes(user0): 22817506 bytes\n",
      "\n",
      "\n",
      "---client_sendsize_list(user1)---\n",
      "total client_sendsizes(user1): 22817561 bytes\n",
      "\n",
      "\n",
      "---client_receivesize_list(user1)---\n",
      "total client_receive sizes(user1): 22817506 bytes\n",
      "\n",
      "\n",
      "---train_sendsize_list---\n",
      "total train_sendsizes: 45635000 bytes\n",
      "\n",
      "\n",
      "---train_receivesize_list---\n",
      "total train_receivesizes: 45635000 bytes\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print('val_acc list')\n",
    "# for acc in val_acc:\n",
    "#     print(acc)\n",
    "\n",
    "print('\\n')\n",
    "print('---total_sendsize_list---')\n",
    "total_size = 0\n",
    "for size in total_sendsize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total_sendsize size: {} bytes\".format(total_size))\n",
    "print('\\n')\n",
    "\n",
    "print('---total_receivesize_list---')\n",
    "total_size = 0\n",
    "for size in total_receivesize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total receive sizes: {} bytes\".format(total_size) )\n",
    "print('\\n')\n",
    "\n",
    "for i in range(users):\n",
    "    print('---client_sendsize_list(user{})---'.format(i))\n",
    "    total_size = 0\n",
    "    for size in client_sendsize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    print(\"total client_sendsizes(user{}): {} bytes\".format(i, total_size))\n",
    "    print('\\n')\n",
    "\n",
    "    print('---client_receivesize_list(user{})---'.format(i))\n",
    "    total_size = 0\n",
    "    for size in client_receivesize_list[i]:\n",
    "#         print(size)\n",
    "        total_size += size\n",
    "    print(\"total client_receive sizes(user{}): {} bytes\".format(i, total_size))\n",
    "    print('\\n')\n",
    "\n",
    "print('---train_sendsize_list---')\n",
    "total_size = 0\n",
    "for size in train_sendsize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total train_sendsizes: {} bytes\".format(total_size))\n",
    "print('\\n')\n",
    "\n",
    "print('---train_receivesize_list---')\n",
    "total_size = 0\n",
    "for size in train_receivesize_list:\n",
    "#     print(size)\n",
    "    total_size += size\n",
    "print(\"total train_receivesizes: {} bytes\".format(total_size))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining `ECG` Dataset Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        if train:\n",
    "            with h5py.File(os.path.join(root_path, 'ecg_data', 'train_ecg.hdf5'), 'r') as hdf:\n",
    "                self.x = hdf['x_train'][:]\n",
    "                self.y = hdf['y_train'][:]\n",
    "        else:\n",
    "            with h5py.File(os.path.join(root_path, 'ecg_data', 'test_ecg.hdf5'), 'r') as hdf:\n",
    "                self.x = hdf['x_test'][:]\n",
    "                self.y = hdf['y_test'][:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx], dtype=torch.float), torch.tensor(self.y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataLoader` for batch generating\n",
    "`torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ECG(train=True)\n",
    "test_dataset = ECG(train=False)\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of total batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414\n",
      "414\n"
     ]
    }
   ],
   "source": [
    "train_total_batch = len(trainloader)\n",
    "print(train_total_batch)\n",
    "test_batch = len(testloader)\n",
    "print(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer = Adam(ecg_net.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of train and each of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 98.14%, train_loss: 0.9237\n",
      "test_acc: 97.35%, test_loss: 0.9317\n",
      "Accuracy of     N : 97 %\n",
      "Accuracy of     L : 99 %\n",
      "Accuracy of     R : 99 %\n",
      "Accuracy of     A : 82 %\n",
      "Accuracy of     V : 98 %\n",
      "WorkingTime: 365.4895222187042 sec\n"
     ]
    }
   ],
   "source": [
    "ecg_net.load_state_dict(global_weights)\n",
    "ecg_net.eval()\n",
    "ecg_net = ecg_net.to(device)\n",
    "\n",
    "# train acc\n",
    "with torch.no_grad():\n",
    "    corr_num = 0\n",
    "    total_num = 0\n",
    "    train_loss = 0.0\n",
    "    for j, trn in enumerate(trainloader):\n",
    "        trn_x, trn_label = trn\n",
    "        trn_x = trn_x.to(device)\n",
    "        trn_label = trn_label.clone().detach().long().to(device)\n",
    "\n",
    "        trn_output = ecg_net(trn_x)\n",
    "        loss = criterion(trn_output, trn_label)\n",
    "        train_loss += loss.item()\n",
    "        model_label = trn_output.argmax(dim=1)\n",
    "        corr = trn_label[trn_label == model_label].size(0)\n",
    "        corr_num += corr\n",
    "        total_num += trn_label.size(0)\n",
    "    print(\"train_acc: {:.2f}%, train_loss: {:.4f}\".format(corr_num / total_num * 100, train_loss / len(trainloader)))\n",
    "\n",
    "\n",
    "# test acc\n",
    "with torch.no_grad():\n",
    "    corr_num = 0\n",
    "    total_num = 0\n",
    "    val_loss = 0.0\n",
    "    for j, val in enumerate(testloader):\n",
    "        val_x, val_label = val\n",
    "        val_x = val_x.to(device)\n",
    "        val_label = val_label.clone().detach().long().to(device)\n",
    "\n",
    "        val_output = ecg_net(val_x)\n",
    "        loss = criterion(val_output, val_label)\n",
    "        val_loss += loss.item()\n",
    "        model_label = val_output.argmax(dim=1)\n",
    "        corr = val_label[val_label == model_label].size(0)\n",
    "        corr_num += corr\n",
    "        total_num += val_label.size(0)\n",
    "        accuracy = corr_num / total_num * 100\n",
    "        test_loss = val_loss / len(testloader)\n",
    "    print(\"test_acc: {:.2f}%, test_loss: {:.4f}\".format( accuracy, test_loss))\n",
    "\n",
    "# acc of each acc    \n",
    "class_correct = list(0. for i in range(5))\n",
    "class_total = list(0. for i in range(5))\n",
    "classes = ['N', 'L', 'R', 'A', 'V']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        x, labels = data\n",
    "        x = x.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = ecg_net(x)\n",
    "        labels = labels.long()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "# Let's quickly save our trained model:\n",
    "PATH = './ecg_fd.pth'\n",
    "torch.save(ecg_net.state_dict(), PATH)\n",
    "\n",
    "end_time = time.time()  # store end time\n",
    "print(\"WorkingTime: {} sec\".format(end_time - start_time))\n",
    "#     sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
